---
layout: post
title: 一站式 Machine Learning 基础
category: ML
tags: Machine Learning
description: machine learning
---

<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>

## 1 背景知识

此部分主要是一些通用的背景知识，不局限于机器学习领域，在其他领域也有广泛应用。

### 1.1 频率派和贝叶斯派

**频率学派**<br>
频率学派相信一个概率事件发生的概率是存在唯一的True Value的，客观存在，只是人们不知道，我们想要知道这个真值就要用大量的重复独立实验去逼近，根据大数定理，在实验次数足够大的情况下，事件发生的频率无限逼近概率

**贝叶斯学派**<br>
贝叶斯学派认为事件发生的概率不是一个确定的值，而是一个分布，A指参数，P(A)称为先验概率，表示参数取某个特定值的概率，这个是利用其它先验知识获得的。如果先验函数是均匀分布，那么贝叶斯方法等于频率方法，先验为均匀分布也就是所有参数情况的概率一样，也就是没有先验，先验的作用就是在于能提前给定一些信息，有偏向。P(B\|A)表示似然函数，意思是在A为某个值的情况下，发生某个特定事件B的概率。P(B) 是发生某个事件B的概率，他是一个累计的结果，是全概率公式计算所得 = 在参数A1情况下发生B的概率*参数A1的概率 + 事件A2情况下发生B的概率\*参数A2的概率 + ... 在参数An发生的情况下发生B的概率\*参数An的概率。P(A\|B)为后验概率， 发生某个事件的情况下，参数为A的概率。那么实际使用中，例如贝叶斯分类器，通常取用使得后验概率最大的参数

![bayes](/assets/img/ML/one-stop-machine-learning/bayes.jpg)

贝叶斯学派和统计学派的区别可以看成概率和统计的区别，概率是已知模型和参数推测结果，统计是已知结果倒推出模型和参数。

**贝叶斯公式的理解**<br>
以一个例子来理解贝叶斯公式，假设事件B表示车辆警报响了，事件A表示车辆被砸，P(A\|B)表示警报响了的情况下车子被砸的概率，P(B\|A)似然函数表示车子被砸了警报响的概率，姑且认为是1. P(A)先验概率表示车辆被砸的概率，利用先验知识知道这个值很小。P(B)表示警报响的概率，需要考虑很多情况，由车辆被砸导致的警报响，还是其他原因导致的警报响。

有两个理解点
1. 如果P(B)越大，也就是说警报概率越大，越常见，那么在车辆被砸概率一定的情况下，P(A\|B)越小，反之如果警报概率小，而且只要车辆被砸就会引发警报，那么在车辆被砸概率一定的情况下，后验概率大。也就是说考虑到了警报响这件事本身的概率，换句话说考虑到了非车辆被砸情况导致的警报响。
2. 考虑先验，我们提前知道P(A)很小，分子很小， P(A\|B) 在其他已知的情况下，不会很大。先验知识通常由已知数据统计而来，数据量越大，先验概率越准

**最大似然估计(MLE)**<br>
似然函数P(B\|A) 表示在不同参数下，事件B发生的概率，现在事件B已经发生，那么似然函数最大对应的那个参数值最有可能导致事件B的发生，我们更有信心去相信模型的参数是似然函数最大对应的参数。

拿硬币的来举例，如果现在事件是 ‘反正正正正反正正正反’。硬币正向向上的概率为θ，那么似然函数是f(x0,θ)=(1−θ)×θ×θ×θ×θ×(1−θ)×θ×θ×θ×(1−θ)=θ^7(1−θ)^3=f(θ) , 此时如果画出似然函数的图像可以看出θ为0.7左右的时候似然函数概率最大，在该事件发生的情况下，用最大似然估计的方法估计出的正面向上的概率值是0.7。但是这仅仅根据一次投掷结果就推测实在有点武断，需要引入先验概率，也就是最大后验概率估计。

![mle](/assets/img/ML/one-stop-machine-learning/MLE.png)

**最大后验概率估计(MAP)**<br>
最大后验概率，就是最大化似然函数和先验函数的乘积(分母事件已经发生，边缘概率已知为定值)，还是拿上面那个例子来举例，已经发生的事件是 ‘反正正正正反正正正反’，似然函数是f(θ) ，我们根据先验知识，先验的认为P(θ) 满足一个均值为0.5，方差很小的正态分布，计算P(B\|θ)*P(θ)，其实就是对之前的似然函数，用先验函数进行修正，此时后验函数最大值向0.5偏移。那么如果我们加大实验次数呢？似然函数会越来越收窄，此时先验函数对似然函数的“修正作用”越来越小，最大后验概率估计结果接近最大似然估计。

**MLE 和 MAP的区别联系**<br>
MLE 可以看成把先验函数视为均匀分布的MAP, MAP在实验次数最够多的情况下结果和MLE一样。

**Reference**<br>[详解MLE,MAP以及贝叶斯公式的理解](https://blog.csdn.net/u011508640/article/details/72815981)<br>[频率学派还是贝叶斯学派](https://www.sohu.com/a/215176689_610300)

### 1.2 距离的衡量

作为距离测度满足几个条件
- 非负性 d(x, y)>=0
- 自反性d(x, y) = 0 当且仅当 x  ==  y
- 对称性d(x, y) = d(y, x)
- 三角不等式 d(x, y) < d(x, z) + d(z, y)

**闵科夫斯基距离**

$$
L_p(x_i,x_j) = (\sum_{l=1}^{n}|x_i^l - x_j^l|^p)
$$

p=2时称为欧式距离；当p=1时，称为曼哈顿距离；当p为无穷大时，是各个坐标距离的最大值，称为切比雪夫距离。

**余弦距离**

$$
cos\theta = \frac{\sum_{1}^{n}(a_i\times b_i)}{\sqrt{\sum_{1}^{n}a_i^2}\times\sqrt{\sum_{1}^{n}b_i^2}}
$$

取值范围-1到1,1表示完全相同，-1表示完全相反，0表示独立，其他表示相似性或者相异性。

**皮尔森相关系数**<br>
两者的协方差/标准差的乘积
$$
Corr(x,y) = \frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}}
$$

**Jaccard 距离**

$$
Jaccard相似系数：\quad J(A,B) = \frac{|A \cap B|}{|A\cup B|} \quad A与B交集占A与B并集的比例\\
Jaccard距离：\quad J(A,B) = \frac{|A\cup B|-|A \cap B|}{|A\cup B|} \quad 1-jaccard相似系数
$$

**距离的应用**
1. 对于标量特征；主要是Lp距离，皮尔森距离等特别注意的是**为了避免数值大的特征支配距离衡量，需要进行数值归一化**
2. 对于二元特征；一般采用“取值不同的同位属性数/单个元素的属性位数”，来衡量距离；刚才所说的相异度应该叫做对称二元相异度。现实中还有一种情况，就是我们只关心两者都取1的情况，而认为两者都取0的属性并不意味着两者更相似。例如在根据病情对病人聚类时，如果两个人都患有肺癌，我们认为两个人增强了相似度，但如果两个人都没患肺癌，并不觉得这加强了两人的相似性，在这种情况下，改用“取值不同的同位属性数/(单个元素的属性位数-同取0的位数)”来标识相异度，这叫做非对称二元相异度。如果用1减去非对称二元相异度，则得到**非对称二元相似度**，也叫**Jaccard系数**，是一个非常重要的概念。
3. 对于类别特征；可以先one-hot再采用二元特征方式衡量，也可以用”取值不同的同位属性数/单个元素的全部属性数”衡量。
4. 对于序数变量；序数变量是具有序数意义的分类变量，通常可以按照一定顺序意义排列，如冠军、亚军和季军。对于序数变量，一般为每个值分配一个数，叫做这个值的秩，然后以秩代替原值当做标量属性计算相异度。
5. 对于向量；由于向量有方向，一般采用cosine距离衡量，cosine衡量的是相似性而不是相异性

**Reference**<br>[常见的距离测度](https://blog.mythsman.com/post/5d2d440da2005d74040ef6e8/)

## 2 基础知识

此部分主要涉及机器学习相关的通用基础知识，相较于背景知识，此部分更加贴近机器学习领域，但是大多是不同模型之间通用的知识，比较泛化。其中梯度和激活函数的部分，虽然在传统机器学习领域也有涉及，但是在深度网络中才更加的大放异彩，故放在深度学习的基础知识部分进行记录。

### 2.1 机器学习的本质

> 机器学习的本质就是对问题真实模型的逼近

我们希望知道我们选择的假设解和问题的真实解之间的差距，假设解和真实解之间的差距就是**风险** ， 风险的真实大小我们无从得知，我们只能从测试样本的模型预测结果和真实结果之间的差距去表示，因为测试样本是标记过的样本，真实值已知，这个测试集和真实值的差距就是**经验风险**， 之前的机器学习方法的优化目标是**经验风险最小化原则**，例如极大似然估计，当模型是条件概率分布，损失函数是对数函数的时候，经验风险最小化就是极大似然估计

后来发现只要足够复杂的模型，去记住样本集中每一个样本的特征，就能够在样本集上完成100%分类正确，但是在样本集以外错误率很高，overfitting。经验风险最小化原则训练出的模型能描述真实问题的**前提是经验风险和真实风险能够无限逼近，具有一致性**。可是样本集的分布是不是代表真实样本分布，这要画上一个问号，训练模型在此样本集的基础上做到了经验风险最小，真实样本中当然会出现误差变大的情况。

因此，真实风险不能只用经验误差去描述，应该有两部分组成：**经验风险，模型在样本上的误差；置信风险，代表多大程度上相信模型在未知样本上的结果，**此时的误差叫做***泛化误差界***，置信风险我们无法精确衡量，我们只能估计一个大概的置信区间，使得整个误差只能计算上界，因此叫做泛化误差界。置信风险和两个量有关，样本集的数量n，n越大，我们越有理由相信模型在未来真实表现更好；另一个是模型的VC维h，VC维越高，模型越复杂，越容易过拟合，于是经验风险最小化原则，变成了**结构风险最小化原则**

**泛化误差界**：R(w)(真实风险) ≤ Remp(w)（经验风险）+Ф(n/h)（置信风险）

$$
R(f)\leq \hat{R(f)} + \varepsilon(d,N,\delta)\\
\varepsilon(d,N,\delta)=\sqrt{\frac{1}{2N}(logd+log\frac{1}{\delta})}
$$

N代表样本数量，d代表假设空间的数量，VC维越高，模型越复杂，参数越多，假设空间大小越大

$$
R_{sm}=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i)) + \lambda J(f)
$$

在统计学习方法中，结构风险等于经验风险加上惩罚项，当模型是条件概率分布，损失函数是对数损失函数，复杂度由模型先验概率表示时，结构风险最小化就是最大后验概率估计

### 2.2 One-Hot 编码

**为什么使用one-hot编码？**
1. 使得模型可以解决类别问题，计算机只能处理数值，不能处理属性，例如‘蓝色’，需要把属性硬编码成数字，然后对编码结果进行one-hot
2. 距离计算合理，属性硬编码之后，数值之间的差异不代表距离的大小，只代表不同的属性取值，one-hot之后距离差相同，更加合理

**Python常用编码API**<br>
pandas pd.get_dummies()

- 同时适用于字符型和数字型的数据
- 因为没有onehot-encoder的‘记忆功能’，如果不能同时对测试集和训练集做one-hot的话，会出现维度错误

skilearn OneHotEncoder()
- 只适用于数值型数据
- 如果训练集足够大，出现了所有可能取值，那么transform 函数可以对未知测试集适用

### 2.3 Bias-Var Trade-Off

bias 和variance 还有随机误差是训练模型和真实模型之间误差的三个组成部分。随机误差这个无法避免，暂不讨论。

bias：“用所有可能的训练数据集训练出的所有模型的输出预测结果的期望”与“真实模型”的输出值（样本真实结果）之间的差异，也就是在衡量对样本的拟合效果，拟合的越好，bias越小，但是越容易过拟合，一般增加模型复杂度，有助于降低bias

variance：是“不同的训练数据集训练出的模型”的输出值之间的差异，也就说对于随机样本预测误差的波动大小，约束模型复杂度有助于降低variance。

很明显，variance和bias之间存在一个取舍，加大模型复杂度，bias会变小，但是同时模型容易过拟合，variance变大，反之亦然。

![bias-variance-tradeoff](/assets/img/ML/one-stop-machine-learning/variance-bias-tradeoff.jpg)

bias-variance曲线大概是这样的一个样子，当total 在拐点右边时，模型过拟合，左边时，模型欠拟合。

欠拟合的标志
- 训练集误差大
- 验证集和测试集误差差不多大

过拟合标志
- 训练集误差小
- 测试集误差大

 **Reference**<br>[方差偏差均衡](https://plushunter.github.io/2017/04/19/机器学习算法系列（18）：方差偏差权衡（Bias-Variance Tradeoff）/)

### 2.4 ROC &AUC

要谈到ROC图和AUC的值，首先要提到混淆矩阵

![confusion-matrix](/assets/img/ML/one-stop-machine-learning/confusion-matrix.png)

ROC曲线**横坐标FPR**，**纵坐标TPR，**样本中的真实正例类别总数即TP+FN。TPR即True Positive Rate，**理解为正样本的召回率**，TPR = TP/(TP+FN)。同理，样本中的真实反例类别总数为FP+TN。FPR即False Positive Rate，FPR=FP/(TN+FP)，**理解为误判为正样本的比例**。

接下来我们考虑ROC曲线图中的四个点和一条线。第一个点，**(0,1)（左上角，完美）**，即FPR=0, TPR=1，这意味着FN（false negative）=0，并且FP（false positive）=0。Wow，这是一个完美的分类器，它将所有的样本都正确分类。第二个点，**(1,0)（右下角，最差）**，即FPR=1，TPR=0，类似地分析可以发现这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。第三个点，**（左下角，把所有样本分为负样本）**，即FPR=TPR=0，即FP（false positive）=TP（true positive）=0，可以发现该分类器预测所有的样本都为负样本（negative）。类似的，第四个点**（1,1）（右上角，把所有样本分为正样本）**，分类器实际上预测所有的样本都为正样本。经过以上的分析，我们可以断言，ROC曲线越接近左上角，该分类器的性能越好。

下面考虑ROC曲线图中的虚线y=x上的点。这条对角线上的点其实表示的是一个采用随机猜测策略的分类器的结果，例如(0.5,0.5)，表示该分类器随机对于一半的样本猜测其为正样本，另外一半的样本为负样本。

**那ROC曲线是怎么画出来的呢？**<br>
假设有N个样本，对应的概率值p（取值0-1）分别为p1，p2.... pn, 分别把pi作为threshold 大于threshold的判别为1，小于的判别为0，就可以得到N个ROC曲线上的点，当我们将threshold设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当threshold取值越多，ROC曲线越平滑。p值越小，越多的样本被划分为正样本，TPR上升，同时更多的负样本被误判为正样本，FPR上升。曲线像右上角移动；反之P值越大，越少的样本被划分为正样本，TPR,FPR同时下降，曲线像左下角移动。

**AUC的值就是曲线下的面积（area under curve）AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值**。

ROC曲线和AUC的值有一个很好的特性就是当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变；这个在验证模型效果的时候很好用，做k-fold cv的时候验证集正负样本分布式变化的，如果衡量指标有较大的变化，不好衡量模型的具体效果

**AUC计算方法**<br>
既然AUC描述的是正样本概率值大于负样本的概率，那么假设正样本M，负样本N，一共有M*N个正负样本对

1. 正样本预测概率大于负样本 记为1
2. 正样本预测概率等于负样本 记为0.5
3. 正样本预测概率小于负样本 记为0
4. AUC = sum/ M*N

或者就从定义的角度出发，画出ROC曲线，计算曲线下的面积。

**Reference**<br>[AUC，ROC我看到的最透彻的讲解](https://blog.csdn.net/u013385925/article/details/80385873)

### 2.5 L1, L2正则化

范数的作用就是把向量映射到[0, )的范围只有零向量可以取到0，用**向量的范数衡量两个向量的距离**
Lp-norm的定义

$$
||X||_p :=(\sum_{i=1}^{n}|x_i|^p)
$$

L1,L2的各自特点
1. L2一定只有一条最优预测线，L1可能有多个
2. L1对异常值较之L2不敏感
3. **L1输出稀疏，把不重要的特征置位0，特征选择，L2则是保留所有特征，把特征贡献尽量压缩到最小，L1，L2共同使用就是把不重要的特征权重置为0，重要的特征的权重尽可能的低**。从函数和梯度图可以看出L1的梯度无论取值大小，只能取+1，-1.稳步向零值逼近，但L2的梯度随着权重w取值变小梯度也变小，最后会无限逼近为0，导致权重很难到0，只能尽可能的小。
4. L1在0处不可导，L2处处可导，计算方便
5. L0是计算非零个数，偏向于使更多的特征权重为0，但是L0是离散值不好求解优化，L1是L0的最优凸近似，所以一般采用L1

L1,L2的函数图像和对应导数图像

![img](/assets/img/ML/one-stop-machine-learning/l1l2-d.jpeg)

![img](/assets/img/ML/one-stop-machine-learning/l2l2d.png)

**Reference**<br>[l1正则与l2正则的特点是什么，各有什么优势？](https://www.zhihu.com/question/26485586)

### 2.6 分类问题Metric

$$
precision(精密度) = \frac{TP}{TP+FP} \\
accuracy(准确度) = \frac{TP+TN}{TP+TN+FP+FN}\\
recall(召回率) = \frac{TP}{TP+FN}\\
F1: \frac{2}{F1} = \frac{1}{Precision} + \frac{1}{Recall} -> F1=\frac{2TP}{2TP+FP+FN}
$$

当数据分布不平衡时，accuracy并不是一个好的衡量指标，只需要把所有样本都分类为负样本就能有很好的accuracy，可以考虑使用recall做衡量效果指标，或者想办法解决样本不平衡问题。

### 2.7 模型融合

**Bagging 和 Boosting**<br>
Bagging：**从原始样本集中有放回的随机抽取若干个样本子集，用这样的多个样本子集分别训练多个独立的模型**，最后的预测结果由多个模型表决产生，常见Bagging模型： Random Forest。

优点
- bagging集成和直接训练基学习器的复杂度同阶
- bagging能不经修改的适用于多分类和回归任务
- 使用剩下的样本可以作为验证机进行包外验证（out-of-bag estimate）

Boosting： 提升算法，模型之间是串行关系，后续模型拟合的前序模型的残差，或是拟合目标不变，但是训练样本经过加权，最后由某种方法进行线性组合生成最终的预测结果，常见Boosting模型：AdaBoost，GBDT, XGBoost。

**Bagging和Boosting的区别**

- 样本选择上
  Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。
  Boosting：**每一轮的训练集不变**，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。
- 样例权重
  Bagging：使用均匀取样，每个样例的权重相等。
  Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大，表示如果该样本被分类错误对整体错误的贡献较大，后续分类器会更加关注该样本。
- 预测函数
  Bagging：所有预测函数的权重相等。
  Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。
- 并行计算
  Bagging：各个预测函数可以并行生成。
  Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。

**Stacking & Blending**<br>
stacking 用这个图就可以解释；对于每一个第一层的模型来说，假设总体1000训练集，采用5-fold，每次800训练，200预测，重复5次，得到1000 训练集完整的预测，组合N个第一层模型的1000训练集的预测，1000\*N的矩阵作为第二层的训练集 ；相当于每一个第一层模型就是第二层训练集的一个“feature”，label还是原来的label，**第二层“learning”的东西其实是第一层模型结果和真实label的关系**，如果某一个第一层模型的预测结果和真实结果的相关性很高，该模型对最终输出的影响越大,通常第二层模型采用LR，即LR用来对第一层模型进行加权。

![img](/assets/img/ML/one-stop-machine-learning/stacking.png)

Blending和Stacking的不同就是**不采用k-fold, 而是holdout**，比如1000训练集，分为800训练，200验证，每个model预测这200个验证集，组成200\*N的矩阵，作为下一层的训练集，也就是说stacking下一层有1000样本，而blending只有200样本。

**总结**<br>
bagging： 使用装袋采样来获取数据子集训练基础学习器，分类任务使用投票来融合，回归任务使用平均来融合,引入随机性，用于减少方差，并行集成<br>boosting： 倾向于减少偏差，优化目标就是最小化残差, 串行集成,把弱分类器集成为强分类器<br>stacking：  通过模型的堆叠提高准确度，整个元模型大致分为两层，第一层为若干个其他模型，XGBoost，RF，等等，第二层的输入为第一层的输出，一般采用LR模型把各个模型的输出进行加权融合

**Reference**<br>[集成学习三大法宝-bagging、boosting、stacking](https://zhuanlan.zhihu.com/p/36161812)

### 2.8 交叉验证

**为什么要用交叉验证？** 数据量太少！

**时间序列**<br>
1 Predict Second Half
保证测试集发生在训练集之后，验证集发生在训练集之后，测试集之前
2 日向前链 Forward-Chain

![img](/assets/img/ML/one-stop-machine-learning/forward-chain.jpg)

用一天数据做验证和测试，其他时间作为训练，用一个外部循环来控制多次分割，最后平均一下测试误差

**非时间序列**<br>
K-Fold Cross Validation,K为超参，把数据随机(当样本分布不均匀时，随机分存在把少数样本分在一起，其他组没有少数样本的情况)分为K份，K-1份作为训练集，1份留做test set。使用training set训练模型，用test set测试误差，再选取另一份为test set剩下的K-1份为training set 重复过程K遍，获得平均误差。当K等于样本量时，K折验证变成**留一验证**，即每次只留下一个sample作为test set剩下的全部作为training set。

**K-Fold的作用**
1. 评估模型性能， 用于模型选择，例如我想选XGBoost或者GBDT，在数据集有限的情况下，如果仅仅划分一次training set, testing set，用test set的误差来评估好坏，由于只有一次测试，无法知道模型的泛化能力，理想情况下，当然是增大测试集。但是在不扩展数据集的基础上，K-Fold相当于训练了K个模型，评估了K次，如果这K个模型的平均误差小，一定程度上可以说明该种模型由于另一种(特定模型经过调参，效果肯定会有提升，不能一棒子打死)。
2. 确定超参，例如Random Forest中的DT个数，Grid search中使用K-Fold来确定当前超参取值下的平均误差
3. 在数据量小的时候，避免over-fitting

**Reference**<br>[A Gentle Introduction to K-Fold Cross Validation](https://machinelearningmastery.com/k-fold-cross-validation/)<br>[「交叉验证」到底如何选择K值？](https://zhuanlan.zhihu.com/p/31924220)

### 2.9 过拟合

解决方法
1. 正则化(L1正则化,L2正则化),
2. **扩增数据集**
3. 特征的筛选
4. early stop
5. dropout 按照一定的概率把hidden layer节点输出清0
6. drop connect 按照一定的概率把hidden layer的相连的权值清0
7. 集成学习方法 bagging
8. BN层

过拟合的本质就是因为样本分布无法代表真实分布，根本的解决方法就是让样本分布尽可能的拟合真实分布，所有首选扩增样本集。

### 2.10 对分/打散/VC维

**增长函数**<br>
表示假设空间H，对实例m能标记的最大可能结果数，例如数据集中只有两个样本，二分类问题下，可能的结果只有4种，AA,AB,BA,BB; 此时增长函数值为4，但是可能模型或者样本有限制，使得取值达到不到4，所以增长函数的上限是2^m

**对分**<br>
对于二分类问题来说，H中的假设对数据集D中m个实例赋予标记的每种可能结果称为对D的一种**对分（dichotomy）**。对分也是增长函数的一种上限。

**打散**<br>
打散指的是假设空间H能实现数据集D上全部实例的对分，即增长函数=$2^m$

**VC维**<br>
既然增长函数不一定能取到上限，VC维指得是假设空间H，在数据集D上能实现全打散，即增长函数可以取到上限时，数据集空间的大小，例如二维空间下，模型是线性模型，对于异或的情况不线性可分，则VC维是3，但是如果模型不是线性模型，VC维就增加，说明VC维一定程度上反映了模型的复杂度

## 3 数据清洗

### 3.1 数据修正

结构化数据中可能出现不符合结构要求的数据，例如年龄特征下出现负数，需要手动修正

### 3.2 缺失值填充

- 忽略数据，当缺失值占整体比例很小，且数据量足够的情况下，可以直接忽略掉含有缺失值的样本
- 人工填写缺失值，人工判断什么值适合填入
- 全局固定值填充，例如0
- 属性的均值/中位数填充
- 使用同一个属性上一个/下一个/最近的有效值填充。
- 使用和含有缺失值样本同一类样本相同属性的均值/中位数填充，例如某男性的年龄缺失，就用所有男性样本的平均年龄填充
- 使用回归决策树等工具进行推理；是**最流行的处理方法**

### 3.3 噪声值处理

观察数据 = 真实数据+噪声值，常见的异常值检测方法有正态分布检测，Tukey's Test, 基于模型检测等。正态分布检测方法通过假定样本值分布属于正态分布，统计属性下样本的均值和方差，进而判断样本值发生的概率是否是小概率事件。Tukey's Test基于四分位计算出数据集的最小估计值和最大估计值，超过最小/最大估计值的样本为异常样本,最小估计值是$Q_1-K(Q_3-Q_1)$ 最大估计值是$Q_3+K(Q_3-Q_1)$ 当k=1.5时为中度异常，当k=3时为重度异常

![tukey's test](/assets/img/ML/one-stop-machine-learning/tukeytest.png)

基于模型的检测主要包括基于聚类，基于回归，基于邻近度/相似度，基于密度的异常检测

## 4 数据预处理

### 4.1 数据的归一化

有一个统一的准则，关心变量的值的模型就要归一化，计算距离的都要归一化；只关心变量分布和变量条件概率就不需要归一化。
例如：决策树，几个算法ID3,C4.5,CART都只关系分割之后样本类别分布，概率问题，所以不要归一化
其他的优化算法都要归一化

**1： z-score归一化**

$$
\hat{x} = \frac{x-\mu}{\sigma}
$$

μ，σ 分别是均值和标准差；数学意义把原始数值映射为离均值有多少个标准差

**2：min-max 归一化**

$$
\hat{x} = \frac{x-x_{min}}{x_{max}-x_{min}}
$$

意义是原始数值占原始值域的百分位

**3： 小数定标标准化**

$$
\hat{x}  = \frac{x}{10^j}
$$

其实$j$取决于数据中最大的绝对数，例如如果最大的绝对数是800，则j为3，如果最大绝对数是1030， 则$j$为4

**4：均值归一化**

$$
\hat{x} = \frac{x-\mu}{x_{max} - x_{min}}
$$

值域是-1 ~  +1，意义在于把原始数据映射到原始数据与均值的差占原值域的比例

**5： 向量归一化**

$$
\hat{x} = \frac{x}{\sum_{i=1}^{n}x_i}
$$

意义在于原始数据映射为对总和的贡献度

**需要归一化的模型**
- 神经网络，标准差归一化
- 支持向量机，标准差归一化
- 线性回归，可以用梯度下降法求解，需要标准差归一化
- PCA
- LDA
- 聚类算法基本都需要
- K近邻，线性归一化，归一到[0,1]区间内。
- 逻辑回归

**不需要归一化的模型**
- 决策树： **每次筛选都只考虑一个变量，不考虑变量之间的相关性，所以不需要归一化**。
- 随机森林：不需要归一化，mtry为变量个数的均方根。
- 朴素贝叶斯

**归一化的好处**
1. 提高模型精度，将数据的量纲去掉，使得不同取值范围的数据对最后结果的影响相同，避免被某一个或若干个特征所支配，特别在距离计算时，容易被取值范围大的特征支配。
2. 提高模型的收敛速度,**原因在于数值特别大的奇异样本数据会导致整个样本区间变‘扁’**，因为其他特征取值范围很小，数值大的特征把本应该近似‘圆形’的样本空间'拉扯'成椭圆‘，导致收敛速度变慢，收敛过程波动大，详情请看参考文献2

**Reference**<br>[数据标准化/归一化normalization](https://blog.csdn.net/pipisorry/article/details/52247379)<br>[机器学习笔记：为什么要对数据进行归一化处理？](https://www.cnblogs.com/silence-tommy/p/7113498.html)

### 4.2 特征离散化

**等值分桶**是指每个区间具有相同大小，但是桶中的样本量不确定<br>
**等频分桶**是指桶中样本量基本相同，但是桶的大小是变化的，需要提前做一定得数据分析，分析出数据的分布，来确定桶的上下限<br>
**单变量分组**是指排序后的数据名次即为分桶，相同的数据有相同的桶<br>
**基于信息熵分组**<br>
根据香农公式一个事件的信息量
$$
l(x) = -log_2(p(x))
$$

熵是可能产生的所有信息量的期望

$$
E(x) = -\sum_{i=1}^{n}{p(x_i)}log_2p(x_i)
$$

那么根据信息熵的分组流程如下
1. 数据排序
2. 遍历数据中每一个取值i, 将数据分为两个区间S1,S2,；找到使得两边熵之和最小的分割点(以label值计算熵)，两边熵之和应该是$E=\sum_{i=1}^{n}w_iE_i$ 其中$w_i$ 是区间数据个数占总个数的比例
3. 如果此时总熵大于最小熵的阈值且没有达到最大分组数，则递归对S1,S2进行步骤2指导总熵小于阈值或者达到最大的分组数

Pros
1. 使的**风险均摊**，假设有个特征中产生一个outlier，且这个特征和label是正相关，那么如果这个outlier比average差距很大，这个特征在决定label的时候权重就会特别大，极度倾向于判别为1，相当于预测结果dominated by outlier，这是我们不愿意看到的。
2. 引入非线性，提高模型的表达能力，离散化引入一定的非线性（如果模型是LR，离散化之后，one-hot之后每个特征有单独的权重，**相当于把单个特征拆成多个特征，引入非线性**），后续one-hot特征进行交叉进一步引入非线性，离散化使得后续特征交叉更精细也更方便
3. 减少计算量： 系数矩阵或者向量的点乘或内积运算速度很快

Cons
1. 等宽分组缺点是会将数据不平衡的分到各个区间，有些区间的数据量很大， 同时其他区间的数据量可能很小
2. 等频分组的虽然克服了等宽分组数据量不均匀的问题，但是可能会把相同的数据分到不同的组内
3. 基于信息熵的分组是监督学习过程，需要标签

相关思考：是否可以把one-hot形式扩展成fuzzy logic形式？想法： 如果换为fuzzy logic 形式计算量变大，涉及到很多浮点数的计算，大大降低计算效率，fuzzy logic 的想法在于优化离散区间；例如如果把年龄分桶，分为未成年（0-17），青年（18-25）, 壮年（26-39），中年（40-50），老年（51-） 那么如果一个人A，25岁，B，26岁他们只差一岁，实际生活中他们的兴趣爱好，经历过的事情有大致相同的趋势，代差不明显，可是在离散化之后，他们却属于不同的分组，在后续训练过程中有不同的表达。那么fuzzy logic的优势体现在它可以很好的区分年龄在不同分组的"属于"程度，体现出差异的同时，对于分桶的边界年龄两边的年龄能很大程度上体现它们的一致性。可是这种优势又不及把年龄全部展开，展开成0-100及100以上共102个区间。加上fuzzy logic 的"恐怖"的计算量，one-hot更好用

### 4.3 特征组合

Pros
1. **在不改变输入的情况下引入非线性**，解决非线性问题例如异或问题，其他的例如年龄和性别，可以组合成未成年的小男孩新特征, 这个新特征可能就和玩具枪的购买欲望成正相关。但是在没有新特征之前，购买玩具枪的欲望和年龄，性别是非线性相关的。

Cons
1. 具体哪两个特征之间进行组合需要大量人工的测试，或者大量的先验知识。

改进<br>
GBDT+LR; GBDT的输入就是整个特征集，输入一个样本，GBDT 生成的M颗树，假设每棵树平均有N 个叶子节点，这N个叶子节点中只有一个输出为1（代表样本被分类到了这个叶子节点）那么最终输入到LR的特征维度有M\*N个维度，这其中只有M个特征值为1，其他为0. 这些叶子节点本身就具有了特征选择功能，如果样本被分到某个叶子节点，从root到该leaf node的path就代表一个组合特征。经过GBDT处理过的稀疏特征输入到LR中作为输入训练LR模型。LR的特征空间大小为M\*N，可以在GBDT训练时控制M,N的大小从而控制LR端的特征空间值。

### 4.4 特征选择方法

1. Filter：使用方差、Pearson相关系数、互信息等方法过滤特征，评估单个特征和结果值之间的相关程度，留下Top相关的特征部分。去掉方差小的特征，因为需要特征有分离度，去掉相关系数高的两个特征中的一个，特征保持精简，防止过拟合
2. Wrapper：可利用“递归特征删除算法”，把特征选择看做一个特征子集搜索问题，筛选各种特征子集，用模型评估效果
3. Embedded：可利用正则化方式选择特征，使用带惩罚项的基模型，除了选择出特征外，同时也进行了降纬
4. 稳定性选择：采用不同的特征子集和数据子集，用模型去衡量特征的重要性，然后统计特征被认为是重要的频率，取前k个

### 4.5 特征降维方法

**PCA \#to be completed**

**LDA \# to be completed**

### 4.6 Embedding

Embedding 的本质是降维，化稀疏为稠密（Turns positive integers(indexes) into dense vectors of fixed size），下图是一个embedding 过程图

![062019_2051_1.png](/assets/img/ML/one-stop-machine-learning/feature-embedding.png)

其中m: 表示样本数；feature_num: 表示特征数<br>
特征为稀疏的特征，不一定是one-hot形式，例如样本是文章，feature是文章相关的一些信息，比如category， tags。 tags的总个数可能有10000个，一篇文章可能有10个tag，那么tag对应的列上，该样本就有10个位为1,其他为0。 在计算的时候，不需要计算0 位乘以embedding matrix的结果，只需要计算1 位的计算值。在tensorflow中，先找到1 位的indices，计算结果相加得到embedding之后的结果。其中embedding matrix 是需要训练的，和full-connected layer 的权重偏置一起进行训练。

### 4.7 样本不平衡

- 使用正确的评估标准,当数据不平衡时可以采用Precesion, recall, F1得分MCC, AUC等评估指标。
- 重新采样数据集,如欠采样和过采样。**欠采样通过减少冗余类的大小来平衡数据集**。**当数据量不足时采用过采样**,尝试通过增加稀有样本的数量来平衡数据集,通过使用重复,自举,SMOTE等方法生成新的样本。
- 以正确的方式使用K-fold交叉验证,组合不同的重采样数据集,对多数类进行聚类。

### 4.8 数据抽样

1. 随机采样，分为有放回随机采样和无放回随机采样
2. 分层采样，如果数据有不同的类型，且类型之间的数据差距较大，考虑到最后的采样样本中需要有各个类型的代表，随机采样不能满足要求，需要用分层采样，分为等个数分层采样和等比例分层采样(每个类别的采样数和类别占比一致)
3. 系统抽样；首先数据按照某一规则排序，分为相同数量的若干部分，从第一部分随机抽取k个样本，后续部分采用和第一部分同样的间距抽取k个样本，共同组成抽样样本。

## 5 模型类型

### 5.1 生成式模型和判别式模型

简单来说，判别式模型就是一个模型，输入进去，label就输出；生成式模型是很多个模型组合，一般类别有多少就有多少模型，例如朴素贝叶斯，需要算每一个类的概率值，然后取最大概率值的类作为label

用统计学的角度来看，生成式模型学习了输入和输出的联合概率分布$p(x,y)$对于输入x来说，每个y的概率是多大，都可以知道,判别式模型学习的是条件概率分布p(x\|y)

优缺点
1. 生成式模型通常对数据分布会做一定的假设，在假设成立时，生成式模型可以用较少的数据取得不错的效果，但是不成立时，判别式模型的效果更好
2. 由于现实中数据分布的假设一般是不成立的，所以判别式模型的错误率会比生成式模型低，但是生成式模型需要更少的数据量来让错误率收敛
3. 生成式模型更容易拟合，判别式模型需要解决凸优化的问题
4. 新增类别的时候，判别式模型需要重新训练，生成式模型不需要

### 5.2 参数模型和非参数模型

在统计学中，参数模型通常假设总体(随机变量)服从某一个分布，该分布由一些参数确定(比如正太分布由均值和方差确定)，在此基础上构建的模型称为参数模型；非参数模型对于总体的分布不做任何假设，只是知道总体是一个随机变量，其分布是存在的(分布中也可能存在参数)，但是无法知道其分布的形式，更不知道分布的相关参数，只有在给定一些样本的条件下，能够依据非参数统计的方法进行推断，**非参数模型不是没有参数，反而是参数太多**。

常见的参数模型：Logistic Regression, Linear Regression, Perceptron都是假定目标函数y=ax+b的形式；优点，可解释性强，训练快，拟合所需数据量少；缺点，指定了目标函数形式，只能应对简单的问题，容易欠拟合

常见非参数模型： DT, 朴素贝叶斯,SVM, DNN；优点，可以拟合任意形式的目标函数，拟合效果也通常好于参数模型；缺点，需要大量的训练数据，速度慢，容易过拟合

**Reference**<br>[机器学习中的参数模型和非参数模型理解](https://blog.csdn.net/FrankieHello/article/details/94022594)

## 6 参数调优

机器学习的参数调优过程通常是黑盒优化过程，每次调优的过程给定输入，得到输出，不能得到整体函数或者梯度信息。目前业界常用Grid Search， Random Search， Bayesian optimization。 一般的，Grid Search计算量最大，Random Search在Grid Search中随机抽样，方差大，但是计算量较少,贝叶斯优化应该是计算量最小的超参优化方法，但是效果通常是最好的。

### 6.1 贝叶斯优化

介绍贝叶斯优化之前，不得不提的一个知识点是**高斯过程(Gaussian processes)** <br>
一元高斯分布,图像是熟悉的钟形曲线

$$
p(x) = \frac{1}{\sigma \sqrt{2\pi}}exp(-\frac{(x-\mu)^2}{2\sigma^2}) \quad 式(1)
$$

多元高斯分布，形状可以理解成空间中的钟形“超曲面”，其中$\mu_i,\sigma_i$ 分别表示第$i$维度的均值和标准差 

$$
p(x_1,x_2,x_3...,x_n) = \prod_{i=1}^{n}p(x_i) = \frac{1}{(2\pi)^{\frac{n}{2}}\sigma_1\sigma_2...\sigma_n}exp(-\frac{1}{2}[\frac{x_1-\mu_1}{\sigma_1^2}+\frac{x_2-\mu_2}{\sigma_2^2}+...+\frac{x_n-\mu_n}{\sigma_n^2}]) \quad 式(2)
$$

用矩阵形式表示，其中$\mu\in\mathbb{R}^n$ 均值向量，$K\in\mathbb{R}^{n\times n}$ 协方差矩阵，因为我们假设各维度之间相互独立，所以协方差矩阵是一个对角阵

$$
x-\mu = [x_1-\mu_1,x_2-\mu_2,...,x_n-\mu_n]^T\\
K= \begin{bmatrix}  
\sigma_1^2 & 0 & ... & 0 \\
0 & \sigma_2^2 & ... & 0  \\
...&...&\ddots&...\\
0 & 0 & ... & \sigma_n^2 \\
\end{bmatrix} \\
\sigma_1\sigma_2\sigma_3...\sigma_n = \begin{vmatrix} K \end{vmatrix}^{\frac{1}{2}}
$$

代入式2

$$
p(x) = (2\pi)^{-\frac{n}{2}}\begin{vmatrix}K\end{vmatrix}^{-\frac{1}{2}}exp(-\frac{1}{2}(x-\mu)^TK^{-1}(x-\mu))
$$

简写成

$$
x \sim \mathcal{N}(\mu,K) \quad 式(3)
$$

到如前为止只是分布，**怎么从分布得到过程呢？**首先来看一个一维高斯分布的例子，我们假设每天7点的心率符合一个高斯分布，横轴是心率，纵轴是概率密度值。

![](/assets/img/ML/one-stop-machine-learning/GP1.jpg)

如果我们8点也采样四个点呢？ 8点的心率符合另一个高斯分布, 横轴是7点的心率，纵轴是8点的心率，画出二维等概率密度线

![](/assets/img/ML/one-stop-machine-learning/GP2.jpg)

那如果我们在时间轴上无数个点都采样四个点呢？，那就是无限维空间的一个等概率密度曲面，但是不好画图，我们把时间轴画在横轴，纵轴表示每个时间index对应采样的四个心率值。可以理解成每个时间节点都对应一个高斯分布，在同一个时间节点采样多次，结果是按照高斯分布波动的。跟着时间轴采样一遍就是图中的一条线(一个函数)，重复一遍就是另一条线，再重复就是另外一条线，例子中横轴是时间轴，当然也可以是其他维度。此时**关于点的概率密度函数变成了关于函数的分布**，**无限维高斯分布即为高斯过程**。

![](/assets/img/ML/one-stop-machine-learning/GP3.jpg)

高斯过程定义： 对于输入$x = [x_1,x_2,...,x_n]$ 函数的集合$f(x) = [f(x_1),f(x_2),...,f(x_n)]$ 都符从多元高斯分布 ,高斯过程f 表示为

$$
f(x) \sim \mathcal{N}(\mu(x),k(x,x)) \quad 式(4)
$$

$\mu(x): \mathbb{R}^n \rightarrow \mathbb{R}^n$表示均值函数，返回各个维度的均值，也就是上图中有一条线，表示所有线的均值所在。$k(x,x):\mathbb{R}^n\times \mathbb{R}^n \rightarrow \mathbb{R}^{n\times n}$ 表示协方差函数，表示各个维度的协方差矩阵。一个高斯过程由一个均值函数和一个协方差函数唯一定义，**一个高斯过程的有限维度子集都符合多维高斯分布**。

解释了高斯过程之后，接着是介绍高斯回归方法，假设我们有一个函数$g(x)$ 具体函数形式未知，并且我们只能采样有限点的情况下， 尽可能拟合出目标函数。我们假设目标函数服从高斯过程，先验表示为$f(x) \sim \mathcal{N}(\mu_f,K_{ff})$,我们现在有一些观测数据$(x^\ast,y^\ast)$ 并且假设$y^\ast$ 和$f(x)$服从联合高斯分布

$$
\begin{bmatrix}f(x) \\y^\ast \end{bmatrix} \sim \mathcal{N}(\begin{bmatrix}\mu_f\\\mu_y\end{bmatrix}, \begin{bmatrix} K_{ff} & K_{fy} \\
K^T_{fy} & K_{yy}
\end{bmatrix}) \quad 式(5)
$$

其中$K_{ff} = k(x,x), K_{fy} = k(x,x^\ast), K_{yy} = k(x^\ast,x^\ast)$ ,有

$$
f \sim \mathcal{N}(K_{fy}^TK_{ff}^{-1}y+\mu_f,K_{yy}-K_{fy}^TK_{ff}^{-1}K_{fy}) \quad 式(6)
$$

表示我们给定观测数据之后，$f$依然是一个高斯过程，而且观察式6，发现新高斯过程的均值函数其实是观测点$y$的线性函数，协方差矩阵第一部分是先验协方差矩阵，后一部分是我们**通过已知观测数据得到的分布不确定性的减少量**。总结一下高斯回归的步骤：**首先提出高斯过程先验，基于先验和假设，加上观察到的数据去修正高斯过程的后验均值和协方差。**

理解高斯过程和高斯过程回归之后，贝叶斯优化过程就很顺理成章了，我们在实际应用中，通常不能直接使用grid search方式调参原因如下<br>
- 计算成本高，选择一组参数组合训练，得到表现结果的成本在大数据的背景下通常很高<br>
- 梯度未知，假设不同的参数组合对应的训练效果存在一个函数表达，我们不知道该函数形式，更不知道当前函数梯度，我们没有信息去修正参数组合的选择“方向”<br>
- 倾向于找到全局最优点，无论是grid search 函数random search，我们都不能保证当前找到的最优点是全局最优的<br>

贝叶斯优化通过一种代理优化(surrogate optimization)的方法去在尽可能少的观测数据的情况下，逼近未知的目标函数。假设我们需要优化的超参数是$x$, 其他参数固定时，该超参数对应的模型表现为$p(x)$。首先我们需要几个初始点(冷启动问题，初始点的超参数如何选择?)用“代理函数”(通常为高斯过程)去做高斯过程回归拟合每个输入的均值和方差(如图中虚线和蓝色区域)，虚线越高表示模型的表现均值越大，蓝色区域越高，表示不确定性越大，“潜力”越大。

![](/assets/img/ML/one-stop-machine-learning/bayes-opt.jpg)

现在我们要选择下一个有可能是最优点的输入，很明显我们应该选择均值大且方差大的点，这种点是最有可能是最优点的，这是一个Exploitation-Exploration问题，需要量化均值和方差对选择的影响。通常类似于Bandit，采用$acquisition function = \mu+\alpha\sigma^2$ 即均值加上$\alpha$倍的方差，这其中$\alpha$ 是一个超参数，即**调整超参数方法的超参数**, 下一次选择分数最高的点对应的输入进行观测。重复操作，往往在样本量极小的情况下，也能获得较为优秀的效果。

总结一下贝叶斯优化的过程<br>1. 初始高斯过程先验分布<br>2. 定义acquisition function，初始化几个观测点$x$，观测点$x$在当前先验分布的获取函数值最大。<br>3. 使用观测点$x$对应的参数组合训练模型，得到结果$y$ <br>4. 更新高斯过程先验，更新后的高斯过程作为下一轮迭代的先验<br>5. 找出当前获取函数最大的点作为下一次迭代的候选观测点<br>6. 重复3-5步骤多次迭代<br>7. 基于当前已知的高斯过程，得到最优解

**Reference**<br>[高斯过程 Gaussian Processes 原理、可视化及代码实现](https://zhuanlan.zhihu.com/p/75589452)<br>[贝叶斯优化: 一种更好的超参数调优方式](https://zhuanlan.zhihu.com/p/29779000)<br>[通俗理解贝叶斯优化](https://mp.weixin.qq.com/s/SRBZUtWt17muCzKErZG0ag)

