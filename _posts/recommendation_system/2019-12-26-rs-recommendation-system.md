---
layout: post
title: 推荐系统
category: DeepLearning
tags: recommendation system
description: 推荐系统模型，算法，框架，相关论文
---

## 推荐系统基础知识

### **推荐系统主要有两个目的**

1： 激发用户兴趣，是用户去做某件事情，例如购物，看电影。

2：解决信息过载问题，从大集合中寻找出合适用户的内容。

所以推荐系统同时涉及到**信息检索**和**信息过滤**，不同于搜索场景，有确定的query，用户需求明确； 推荐系统是没有用户的query，需要根据用户画像，内容画像从总体内容池中选出多样性的偏好内容。

### **基本概念**
**A/A test**
两个版本一样的AB Test； 目的在于检查实验平台的完整性，确保两个流量桶的用户分布是相同的，验证后续进行的AB test的有效性，如果AA 测试的结果达到统计显著，则AB Test的结果是不可信的


## 知识图谱
定义：**结构化的语义知识库**
![img](/assets/img/recommendation_system/knowledge_map.jpeg)
节点称为**实体（Entity）**
无向连线称为**关系（Relation）**
知识图谱的**基本单位**： **Entity - Relation - Entity**

知识图谱的**原始输入**：
1. 结构化数据（Structured Data）：关系型数据库
2. 半结构化数据（Semi-structured Data）: JSON,XML
3. 非结构化数据（Unstructured Data）: 图片，视频

**存储方式：**

1. RDF（resource description framework）
2. 图数据库（Neo4j）

**Reference**

[通俗易懂解释知识图谱（Knowledge Graph）](https://www.cnblogs.com/huangyc/p/10043749.html)

##  关联规则挖掘
关联规则描述两个不同事物之间的关联性，假设有两个非空集合x,y 存在 X->Y 则称之为一条关联规则
关联规则的强度由**支持度（support）**和**自信度（confidence）**描述

### 指标具体含义
**相对支持度support**: （x并y）/总样本 ； x，y 同时出现的样本数/总样本数
**相对自信度confidence**： （x并y）/包含x样本数 ； （x并y）/包含y样本数  x，y同时出现的样本数比上x样本数或者是y样本数、
**绝对支持度**就是集合在样本中出现过的次数 = 相对支持度*总样本数

**关联规则挖掘就是找出 support> support threshold的规则 confidence> confidence threshold的规则**， 如果使用穷举法，穷举所有可能的规则，计算量会爆炸，假设一个样本数为N的集合，所有可能的组合Cn1+Cn2 +...+ Cnn-1 = 2^n - 1

关联规则的挖掘大体分两步，给定最小支持度和自信度的前提下：
1. 生成频繁项集（支持度大于最小支持度的集合）
2. 在频繁项集的基础上筛选出满足最小自信度的项集
由于频繁项集的数据量不会很大，所以第二步的运算时间相对较短，主要time complexity 在第一步。

常用Aprior算法简化运算量，aprior算法的两个主要简化思想：
1：如果一个集合是频繁项集，那么它的所有子集合都是频繁项集，例如假设{A,B,C,D}是频繁项集，满足支持度大于最小支持度阈值，那么任何子集例如{A,B,C}的覆盖度一定是比{A,B,C,D}要大的，所以一定满足最小支持度，一定是频繁项集

2：如果一个集合不是频繁项集，即不满足最小支持度，那么任何超集都不是频繁项集，例如假设{A,B}不是频繁项集，那么任何包含{A,B}的集合都不会是频繁项集，超集的覆盖度一定是比当前集合要小的，所以一定不会满足最小支持度

aprior算法的流程大概如下，是一个迭代的过程，一直到不存在新的超集满足要求，假设支持度最低要求为大于等于3，首先计算单个集合的支持度，剔除掉不满足的单个集合，之后进行自由组合，统计新的二元集合的支持度，剔除掉不满足要求的，图中剔除掉了{牛奶，啤酒}，{面包，啤酒}, 利用aprior算法的第二个简化规则，在生成三元集合的时候，任何同时包含{牛奶，啤酒}和{面包，啤酒}的三元集合都剔除掉，不需要计算支持度，因为这些集合是非频繁项集的超集，一定不是频繁项集。最后只剩下一个3元项集，算法迭代结束。在算法迭代过程中，剔除操作之后剩下的集合都是频繁项集，这些集合的数量和所有可能的组合的个数相比，会小很多。在第二阶段的时候，在对这些频繁项集计算他们的自信度，最后筛选出目标集合。

![img](/assets/img/recommendation_system/relation_mining.png)

**Reference**<br>[数据挖掘系列（1）关联规则挖掘基本概念与Aprior算法](https://www.cnblogs.com/fengfenggirl/p/associate_apriori.html)<br>[Fast algorithm for mining association rules](http://rakesh.agrawal-family.com/papers/vldb94apriori.pdf)

## Content Based

**基于Item本身属性**的推荐，计算物品之间的相关性，然后根据用户的历史爱好，推荐给用户相似的物品。主要涉及到三个步骤。1，构造物品特征；2，计算物品之间的相似度；3，判断用户爱好。

### 优缺点

推荐的质量取决于对物品建模的完整和全面程度，仅仅考虑了物品各属性之间的相关性，效果有限，且不适用于冷启动。但是该方法与用户行为独立，可以推荐新产生，用户还没有行为的物品，避免热门物品被反复推荐。

**Reference**<br>[推荐机制 协同过滤和基于内容推荐的区别](https://www.cnblogs.com/fengff/p/10187150.html)

## Collaborative Filtering

**协同过滤的方法是基于用户的**,不考虑物品本身的属性，协同过滤又可以分为三个子类，User Based, Item Based, Model Based.

### UserCF

基于用户对商品的行为，计算行为相似的用户，推荐相似用户的商品给他。首先计算用户的**评分矩阵** m\*n m是用户数，n是物品数。$d_{ij}$表示用户$i$对$j$商品的行为的总分，收藏，购买，点赞等行为都有对应的分数；例如：

| 用户/商品 | 1    | 2    | 3    | 4    | 5    | 6    |
| :-------- | :--- | :--- | :--- | :--- | :--- | :--- |
| A         | 1    |      | 5    | 3    |      |      |
| B         |      | 3    |      |      | 3    |      |
| C         | 5    |      |      |      |      | 10   |
| D         | 10   |      |      |      | 5    |      |
| E         |      |      | 5    | 1    |      |      |
| F         |      | 5    | 3    |      |      | 1    |

第二部计算用户相似度，一般采用cosine距离来衡量两个用户的相似度,计算用户**相似度矩阵**m\*m

|      | A    | B    | C    | D    | E    | F    |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| A    | 1    | 0    | 0.08 | 0.15 | 0.93 | 0.43 |
| B    | 0    | 1    | 0    | 0.32 | 0    | 0.6  |
| C    | 0.08 | 0    | 1    | 0.4  | 0    | 0.15 |
| D    | 0.15 | 0.32 | 0.4  | 1    | 0    | 0    |
| E    | 0.93 | 0    | 0    | 0    | 1    | 0.5  |
| F    | 0.43 | 0.6  | 0.15 | 0    | 0.5  | 1    |

第三部，计算推荐列表，**推荐列表（m\*n）=相似度矩阵（m\*m）x 评分矩阵（m\*n）**

|      | 1    | 2    | 3    | 4    | 5    | 6    |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| A    | 2.9  | 2.2  | 11.0 | 3.9  | 0.8  | 1.2  |
| B    | 3.2  | 6.0  | 1.8  | 0    | 4.6  | 0.6  |
| C    | 9.1  | 0.8  | 0.9  | 0.2  | 2.0  | 10.2 |
| D    | 11.2 | 1.0  | 0.8  | 0.5  | 6.0  | 4.0  |
| E    | 0.9  | 2.5  | 11.2 | 3.8  | 0    | 0.5  |
| F    | 1.2  | 6.8  | 7.7  | 1.8  | 1.8  | 2.5  |

第四步，由于用户之前已经对一些商品有过行为，所以把那些商品去掉，得到最后的推荐列表，取前k个最相关的商品推荐给用户

|      | 1    | 2    | 3    | 4    | 5    | 6    |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| A    |      | 2.2  |      |      | 0.8  | 1.2  |
| B    | 3.2  |      | 1.8  | 0    |      | 0.6  |
| C    |      | 0.8  | 0.9  | 0.2  | 2.0  |      |
| D    |      | 1.0  | 0.8  | 0.5  |      | 4.0  |
| E    | 0.9  | 2.5  |      |      | 0    | 0.5  |
| F    | 1.2  |      |      | 1.8  | 1.8  |      |

### **ItemCF**

基于用户对商品的偏好，把相似商品推荐给他，这里的**相似商品并不是由商品本身的属性决定的，而是用户的行为作为商品的“属性”去计算相似度**，说到底还是只考虑用户行为，而不考虑物品本身的属性。
计算过程也非常相似，区别在于计算时把UserCF的**评分矩阵转置**，再计算商品与商品之间的相似度得到**商品之间的相似度矩阵**。
最后的**推荐列表 = 商品之间的相似度矩阵 X 评分矩阵转置**

### UserCF与ItemCF的对比
Item CF 和 User CF 是基于协同过滤推荐的两个最基本的算法，User CF 是很早以前就提出来了，Item CF 是从 Amazon 的论文和专利发表之后（2001 年左右）开始流行，大家都觉得 Item CF 从性能和复杂度上比 User CF 更优，其中的一个主要原因就是对于一个在线网站，用户的数量往往大大超过物品的数量，同时物品的数据相对稳定，因此计算物品的相似度不但计算量较小，同时也不必频繁更新。但我们往往忽略了这种情况只适应于提供商品的电子商务网站，对于新闻，博客或者微内容的推荐系统，情况往往是相反的，物品的数量是海量的，同时也是更新频繁的，所以单从复杂度的角度，这两个算法在不同的系统中各有优势，推荐引擎的设计者需要根据自己应用的特点选择更加合适的算法。

在非社交网络的网站中，内容内在的联系是很重要的推荐原则，它比基于相似用户的推荐原则更加有效。在社交网络站点中，User CF 是一个更好错的选择，User CF 加上社会网络信息，可以增加用户对推荐解释的信服程度。

### 优缺点

与基于内容的推荐不同，CF不需要对物品严格建模，与物品所处领域无关，但是是基于历史数据的不适用冷启动问题，对于长尾审美，也不能很好的推荐。UserCF计算的是user之间的相似度，更加注重用户所在的兴趣小组，更加注重社会化;ItemCF注重的是用户有过行为的历史物品，所以更加个性化。

在单用户的多样性上，ItemCF比不上UserCF,因为它是基于用户之前有过行为的物品进行的推荐，覆盖面太小；但是在系统层面，ItemCF比UserCF的多样性要好，UserCF倾向于只推荐热门物品， ItemCF可以挖掘出长尾物品。

同时UserCF, ItemCF也各有限制，UserCF推荐的假设是，用户喜欢那些和他有相同爱好的用户喜欢的东西，推荐效果取决于用户有多少"相似用户"，如果一个用户有长尾爱好，则推荐效果可能欠佳。ItemCF推荐的假设是用户喜欢和他之前有过行为的商品相似的商品，如果用户行为的自相似度高，说明假设成立，如果反之，则假设不成立，推荐效果欠佳。

**Reference**<br>[推荐系统UserCF, ItemCF](https://www.jianshu.com/p/ec3de12db6e7)

## LFM

Latent Factor Model隐性因子模型，意在找出用户的兴趣因子。LFM对用户喜欢的物品类别，和物品分属于类别的概率进行建模，如下三个矩阵

![lfm](/assets/img/recommendation_system/lfm.jpg)

R：用户对物品的偏好信息，$R_{ij}$表示用户$i$对物品$j$的偏好程度。P：表示用户对物品类别的偏好矩阵。Q：表示物品属于个类别的比例。从上述图中可以看出用户对物品的兴趣度可以用如下公式表示，推荐兴趣度top N的物品给用户即可。
$$
R(u,i) = \sum_{k=1}^{K}P_{u,k}Q_{i,k}
$$
那么问题来了，class类别数怎么分，P和Q矩阵如何确定。首先class类别数是一个hyper parameter，由先验确定，或者根据推荐结果，进行实验修改。P,Q矩阵参数首先是随机初始化，通过梯度下降方法进行优化迭代，模型学习出来的。那label又是哪里来的呢？R矩阵中如果用户对某个物品有过行为则为1，否则为0，如果推荐场景中能很好的收集**用户负反馈信息**(通常很难获取)，则行为可以为负数。损失函数顺理成章的是
$$
cost = \sum_{(u,i)\in S}(R_{ui}-\hat{R_{ui}})^2 +\lambda||P_u||^2 +\lambda||Q_i||^2
$$
对两个未知参数求梯度
$$
\frac{\partial c}{\partial P_{uk}} = -2\sum_{(u,i)\in S}(R_{ui}-\sum_{k=1}^{K}P_{u,k}Q_{k,i})Q_{ki}+2\lambda P_{uk} \\
\frac{\partial c}{\partial Q_{ki}} = -2\sum_{(u,i)\in S}(R_{ui}-\sum_{k=1}^{K}P_{u,k}Q_{k,i})P_{uk}+2\lambda Q_{ki}
$$
参数更新
$$
P_{uk} = P_{uk} +\alpha(\frac{\partial c}{\partial P_{uk}})\\
Q_{ki} = Q_{ki} +\frac{\partial c}{\partial Q_{ki}}
$$
从整个训练过程中可以看出，我们最终是想要矩阵R，也就是用户对于每个item的兴趣值，在这个过程中，我们得到中间结果矩阵R，也就是用户对于类别的喜好，以及矩阵Q，item属于类别的概率，这里相当于完成了item的自动“聚类”，我们不关心“聚类”的维度划分过程，只需要提供超参也就是类别个数。实际应用中，LFM通常是天级别更新。

**Reference**<br>[使用LFM（Latent factor model）隐语义模型进行Top-N推荐](https://blog.csdn.net/HarryHuang1990/article/details/9924377)

## **用户冷启动**

解决冷启动的方案：
1）**提供非个性化的推荐**
最简单的例子就是提供热门排行榜，可以给用户推荐热门排行榜，等到用户数据收集到一定的时候，再切换为个性化推荐。例如Netflix的研究也表明新用户在冷启动阶段确实是更倾向于热门排行榜的，老用户会更加需要长尾推荐

2）利用用户注册信息（人口统计学）
用户的注册信息主要分为3种：（1）获取用户的注册信息；（2）根据用户的注册信息对用户分类；（3）给用户推荐他所属分类中用户喜欢的物品。

3）**选择合适的物品启动用户的兴趣**
用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。一般来说，能够用来启动用户兴趣的物品需要具有以下特点：
1. 比较热门，如果要让用户对物品进行反馈，前提是用户得知道这是什么东西；
2. 具有代表性和区分性，启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性；
3. 启动物品集合需要有多样性，在冷启动时，我们不知道用户的兴趣，而用户兴趣的可能性非常多，为了匹配多样的兴趣，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣

4）利用物品的内容信息
用来解决物品的冷启动问题，即如何将新加入的物品推荐给对它感兴趣的用户。物品冷启动问题在新闻网站等时效性很强的网站中非常重要，因为这些网站时时刻刻都有新物品加入，而且每个物品必须能够再第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。

5）采用专家标注
很多系统在建立的时候，既没有用户的行为数据，也没有充足的物品内容信息来计算物品相似度。这种情况下，很多系统都利用专家进行标注。

6）**利用用户在其他地方已经沉淀的数据进行冷启动**
以QQ音乐举例：QQ音乐的猜你喜欢电台想要去猜测第一次使用QQ音乐的用户的口味偏好，一大优势是可以利用其它腾讯平台的数据，比如在QQ空间关注了谁，在腾讯微博关注了谁，更进一步，比如在腾讯视频刚刚看了一部动漫，那么如果QQ音乐推荐了这部动漫里的歌曲，用户会觉得很人性化。这就是利用用户在其它平台已有的数据。
再比如今日头条：它是在用户通过新浪微博等社交网站登录之后，获取用户的关注列表，并且爬取用户最近参与互动的feed（转发/评论等），对其进行语义分析，从而获取用户的偏好。
所以这种方法的**前提是，引导用户通过社交网络账号登录**，这样一方面可以降低注册成本提高转化率；另一方面可以获取用户的社交网络信息，解决冷启动问题。

7）**利用用户的手机等兴趣偏好进行冷启动**

Android手机开放的比较高，所以在安装自己的app时，就可以顺路了解下手机上还安装了什么其他的app。比如一个用户安装了美丽说、蘑菇街、辣妈帮、大姨妈等应用，就可以判定这是女性了，更进一步还可以判定是备孕还是少女。目前读取用户安装的应用这部分功能除了app应用商店之外，一些新闻类、视频类的应用也在做，对于解决冷启动问题有很好的帮助。

## 推荐框架
### Recall Layer
常用模型： DSSM, YouTube DNN

**DSSM模型**（Deep Structure Semantic Model）

是有微软提出的用于网页搜索的深度网络模型。
![img](/assets/img/recommendation_system/dssm_arch.png)

原生的DSSM 结构如上，两个深度网络结构分开，深度网络的拓扑结构可以更换，DNN, LSTM 等都可以，其中一个深度网络负责把user的query vector映射到一个低维空间，一个负责把doc vector 映射到和query vector同一个低维空间下。对于每一个<query vector', doc vector'>计算距离，一般采用cosine距离，对最后计算的距离排序就是一定程度上query和doc的匹配程度排序。对于同一类doc 可以共用一个item 侧深度网络，如果需要同时输入不同类型的doc，例如图文和视频，则需要相同结构或是不同结构的不同item侧深度网络，如果此时共用一个user侧深度结构，那么就是dssm的改进型 Multi-view DSSM。

![img](/assets/img/recommendation_system/mv_dssm_arch.png)

**YouTube DNN**

![img](/assets/img/recommendation_system/youtube-dnn.jpg)

**模型组成：**

两个DNN nerual network结构； candidate generation 的输入是用户历史行为，输出是召回的small subset of video from a large corpus, 通过collaborative filtering 进行简单的相关召回

**模型细节：**

把推荐任务看成极限多分类任务；即在时刻*t*，为用户*U*（上下文信息*C*）在视频库*V*中精准的预测出视频*i*的类别（每个具体的视频视为一个类别，*i*即为一个类别）

candidate generation 部分的模型结构图

三层DNN 结构，激活函数式ReLU；训练时，初始化一个video vectors 组成的矩阵。假设最后一层DNN 的输出是1*64维，video matrix的维度是64*80w维，则多分类的输出是一个1*80w维的vector，代表着某个sample被划为80w个不同类别的概率，概率最大的输出是最终结果，和用户实际点击的video计算loss，反向传播，更新权重。线上服务的时候，某个sample经过DNN 结构生成user-vector（整个DNN 结构可以当成一个raw input到user-vector的映射），线上服务的时候，video vector是已经train好了的，直接访问就行。user vector的1*128维 和128*80w做knn操作，取出80w个列向量中和user-vector最相似的top k个。

![img](/assets/img/recommendation_system/youtube-dnn-arc.jpg)

训练集细节：

用户看过的video set是变长的，通过embedding 把每个video map到一个定长的vector，这些vector之间对应位置的值进行“averaging”形成最终代表user watched videos的一个定长的vector，user search 进行同样的操作。其他特征中比较重要的是人口统计学信息，使模型一定程度上可以用于用户冷启动；二元和continuous feature map到[0-1] Attention：**在训练过程中，embedding matrix 是和DNN 网络参数一起梯度下降的。**

对于每个IDs Space 都有一个单独的embedding，大小和IDs space的大小成正比。

Ranking部分模型结构图

![img](/assets/img/recommendation_system/youtube-dnn-ranking.jpg)

与召回层不同的是training 的最后一层是LR结构

训练目标大体是期望观看时长，如果以ctr为优化目标，会偏向于推荐具有迷惑性的video，那么用户虽然点击但是没有观看完的video. 线上服务的时候使用e^(wx+b)作为激活函数，是期望停留时长的近似，也就是某个video最后的score

Label 是曝光的视频是否点击，如果点击，则annotated with 浏览时长


 **衡量召回策略好坏的两个指标：**
-  **召回率**：正确召回的/应该被召回的
-  **准确率**：正确召回的/召回总数

**召回策略主要有三种**:
**基于内容的召回**
分为基于内容标签的召回：将内容画像和用户画像相匹配，基于用户历史浏览过的内容标签，推荐相   似标签的内容； 基于知识的匹配： 基于先验知识，得知某一内容和用户之前浏览过的内容有相关性，  进行召回。
**基于协同过滤的召回（user-based, item-based, model-based）**
user-based: 发现相似用户，进行用户内容的交叉召回， 这种方式的难点在于用户相似度的衡量和近邻数量的选择上，同时用户量很大的情况下，如何实时的计算相似度也是一个难题。
item-based：计算item之前的相关性，召回相关度最高的item，这种方式对比user-based的好处在于item之间的相似度可以线下预处理，在特征维度特别大的情况下，实时性好。
model-based: 训练模型， 根据用户的实时爱好进行召回
**基于知识的召回**
例如已知复联2是复联的续集，那么看过复联的用户对复联2的兴趣从常理的角度看应该是很高的，基于这个考虑，加上已经提前知道的“知识”，进行基于知识的召回。


### Score Layer
打分层常用模型：wide&Deep , DNN
**Wide&Deep 模型**

**![图3 Deep&Wide模型结构图](/assets/img/recommendation_system/wide&deep.png)**

[模型paper地址](https://arxiv.org/pdf/1606.07792.pdf)

笔记：

为什么要组合wide && deep 模型？
**Pros：**
- Memorization(记忆)：学习出现的规律，从发生过的记录中学习规律，可以通过a wide set of crossed feature 交叉特征来学习，LR模型加上大量的特征工程可以很好学习已知的特征组合。
- Generalization(泛化)：学习unseen feature combination，通过embedding操作实现，embedding操作一般在DNN中使用
- 组合wide and deep 结构的模型，使得模型同时具有拟合过去历史的能力和一定的泛化能力。

**Cons：**
embedding 操作可能会造成over-generalized 的情况。当user-item interaction are sparse and high-rank的时候，embedding操作会使得很多原本相关性不大的事物被推送给用户。
DNN 的解释性一直是一个问题，假设原始输入特征100w维，1000w个sample，假设embedding matrix的维度为100w*128，DNN网络的输入是1000w*128维的matrix，embedding操作将100w维映射到了128维，这128维代表的含义是不知道的。整个embedding层加上后续的DNN 网络可以看成一个黑匣子，100w维特征的1000w个sample输入，输出了1000w个结果。单个特征对于结果的影响是不知道的，DNN 网络中权重不代表特征对于结果的贡献度。LR则是interpretable的，最后的结果就是特征值加权求和的结果，特征对于最后结果的贡献程度取决于权重。
LR虽然解释性强，但是需要大量的人工去进行特征组合，LR “记忆”能力强，泛化能力弱，可以通过增加一些泛化的组合特征增强LR的泛化能力（例如：用户看过军事&&用户看过历史）

**模型细节**
wide侧：
generalized linear model（LR） 特征有raw input feature 和组合特征
deep侧：
DNN structure with embedding matrix
deep 和 wide 侧通过weighted sum + bias进行连接，取sigmoid，as prediction

**训练方式：**
Joint training 而不是Ensemble；Joint training 和 ensemble的区别在于joint training同时训练joint model，把joint model 当成一个模型来梯度下降，wide侧只需要补充deep部分memorization能力的不足就行，不需要一个庞大的feature set。ensemle 训练方式是两个模型单独训练，同时需要达到各自的期望效果，那么单独一个模型通常需要增大feature数量或者模型深度才可以达到一个reasonable的accuracy。

**优化方法：**
back propagating
wide侧： Follow-the-regularized-leader(FTRL) algorithm with L1 regularization
deep侧： AdaGrad

**训练数据**
label： 用户是否安装了某个app（google play）
vocabularies： 特征ID 化，把categorical类型特征映射到integer ID（对于那些满足最低出现次数的特征），continuous 特征映射到[0-1]
wide侧的特征包含，用户安装的app和曝光过的app记录
deep侧对于每个categorical feature 有一个32维的embedding。deep 侧**原始特征**包含user安装过的app曝光过的app，人口统计学信息，基本信息，device class等

### Ranking layer

经过召回队列返回的文章还是有千甚至万，十万的量级，可是用户一次刷新只能返回十篇文章，怎么从万篇文章中找出这十篇文章就是打分层需要干的事情了。涉及到的领域就是Learning to rank，排序学习。

什么样的排序是一个好排序，需要指标去衡量，一篇文章排在第一位而不是第二位，需要背后的数字去支撑。在搜索环境下，用户有具体的query，衡量一个返回结果的好坏，看结果和query的相似度，越相似的结果理应排在最前面；与搜索场景类似但也有不同，信息流推荐场景下，一个文章的位置要综合多方面的考虑，是把点击率最高的文章放在前面，还是期望停留时长最长的放在前面，亦或是多方面的考虑，出于商业化的需要，返回结果中往往掺杂着广告，商业化和用户满意度的权衡也是一个很重要的考虑点。

**推荐结果指标化主要有两个方面：
1： 衡量单个推荐结果本身的好坏（例如推荐结果多少程度上符合搜索query）
2：衡量返回10篇文章整体的好坏（10篇文章固定的情况下，如何排列才是最好的结果）

**指标的演化流程从P-R， Discounted Cumulative Gain, Expected Reciprocal Rank**
**P-R** 准确率的定义和recall层相同，准确率是相对于召回结果（被认为是相关的文章，可能是真相关，也可能是假相关）来说，召回的结果中正确的比率，所以叫准确率， 召回率是对整个内容库（内容库是所有和query相关的文章）来说的，对于一个request，召回结果中正确的数量占总内容库的比例。**
**但是P-R 没有考虑到位置因素，TRUE,FALSE的分类也太过粗糙。**
**Discounted Cumulative Gain**
**假设一屏有p篇文章，第一篇文章和query的相似度为rel1，第二篇为rel2，总列表的指标就是下面公式加权出来的结果，位置越靠前的文章的相似度对总分的影响最大。**
![img](/assets/img/recommendation_system/discounted_cumulative_gain.png)

**Expected Reciprocal Rank** 
在DCG的基础上考虑了前面文章的相关性
![img](/assets/img/recommendation_system/ERR.png)
（1-Ri）代表文章的相关度，如果前面的文章的不相关度越大，那么该文章的相关度对总分的影响就越大。



排序层的样本生成方式可以分为： pointwise, pairwise, Listwise.
pointwise： 给每个样本一个具体的分数，可以是点击率或者其他数值
pairwise： 没有具体的数值，但是知道任何两个样本之间的好坏关系
Listwise： 一个列表，包含了所有样本的好坏排序，但是具体好多少，或者坏多少，不知道。



**在线排序分层模型**
![img](/assets/img/recommendation_system/online-rank.png)

scene dispatch： 场景分发，划分不同的业务类型
traffic distribution： 流量分发，包含模型分发和流量分桶，将总流量分为不同的桶，对每个模型也分为一定配额的桶，如果流量和模型分到同一个桶，那么该部分的流量就会走到该模型。

 

## 反馈体系
**显示评分**：推荐系统推送给用户的明确的评分系统，比如为对商品的喜爱程度从1到10打分。
**隐式评分**：用户的一些特定行为可以解释为正向或是负向的反馈，例如用户购买某种商品可以解释为用户对于该类商品的正反馈，又或者是用户刷新信息流但是没有点击的动作可以解释为用户对于曝光的信息流都不感兴趣。可是隐式反馈的解释并不是总是正确的，例如用户想给父母买老年手机，搜索老年手机这个行为会被解释为用户对该型号手机感兴趣，并在用户实际购买了老年人手机之后持续一段时间的曝光，可是用户在完成购买行为之后就对老年人手机不感兴趣了，需要一个负反馈机制去抵消正反馈机制带来的“错误”。