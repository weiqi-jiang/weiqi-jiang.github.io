---
layout: post
title: 一站式深度学习基础
category: DeepLearning
tags: deep learning
description: basic knowledges among deep learning field
---

## 1 基础知识

此部分涉及到的知识有一定的理解门槛，如果基础知识有遗忘或者掌握不牢，参见一站式机器学习前部背景知识部分，此文不再重复。

### 1.1 常见损失函数

![loss-func](/assets/img/deeplearning/one-stop/loss-func.png)

**MSE**

平方损失函数即均方误差(MSE)又叫做L2损失，对异常值敏感，某一个异常值可能导致损失函数波动太大。

**MAE**

绝对损失函数即平均绝对误差(MAE)又叫做L1损失，导数可能不连续。

基于上面两个损失函数各自的优缺点，有人提出改进的huber loss function

**Huber Loss Function**

![huber_loss](/assets/img/deeplearning/one-stop/huber_loss.png)

只有在误差小于某个数时，才使用MSE，避免损失函数被异常点支配。

**条件熵**

两个随机变量x,y的联合熵

$$
H(x,y) = -P(x,y)logP(x,y)
$$

在x发生的条件下，y带来的新的熵称为x的条件熵H(Y|X) 衡量已知随机变量x的情况，y的不确定性H(Y|X) = H(X, Y) - H(X)

![img](https://uploadfiles.nowcoder.com/images/20190315/311436_1552628862555_DBA6F761056A8FA361E96F7E44D51F7B)

**互信息**

$$
I(x,y) = \sum p(x,y)log^{\frac {p(x,y)}{p(x)p(y)}}
$$

I(X,Y)=D(P(X,Y)||P(X)P(Y))

**交叉熵**

$$
L = -[ylog\hat{y} + (1-y)log(1-\hat{y})]
$$

二分类下当y = 1

$$
L = -log\hat{y}
$$

当y = 0

$$
L = -log(1-\hat{y})
$$

两者的函数图像都是接近正确分类时，损失函数越小，而且隔得越远，交叉熵越大

注意：**一般用神经网络解决多分类问题，会在输出层设置和类别数量一致的节点数，交叉熵衡量的是两个概率分布之间的相似度，label是概率分布，但是神经网络的输出不是概率分布，需要用softmax把神经网络的输出映射到概率分布**

交叉熵可以从两个方向去理解：

1 我们如果设sigmoid预测输出为y且真实类别也是y的概率定义表示为![[公式]](https://www.zhihu.com/equation?tex=P%28y%7Cx%29%3D%5Chat+y%5Ey%5Ccdot+%281-%5Chat+y%29%5E%7B1-y%7D)，取对数之后和交叉熵就差一个负号，我们想最大化这个概率，等价于最小化这个概率的负数于是就得到交叉熵损失函数

2 从KL散度推导到交叉熵损失函数

相对熵又称KL散度,如果我们对于同一个随机变量 x 有两个单独的概率分布 P(x) 和 Q(x)，我们可以使用 KL 散度（Kullback-Leibler (KL) divergence）来衡量这两个分布的差异，然后就自然的发现交叉熵其实就是KL散度的第二部分，以为KL散度表征是两个概率分布的差异，所以越小越好，自然的KL散度第一部分固定，那么最小化交叉熵就好

![kl1](/assets/img/deeplearning/one-stop/KL.png)

![WeChat Screenshot_20190812224516](/assets/img/deeplearning/one-stop/KL2.png)

**Reference：**

[简单的交叉熵损失函数，你真的懂了吗？](https://zhuanlan.zhihu.com/p/38241764)

[一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉](https://blog.csdn.net/tsyccnh/article/details/79163834)

### 1.2 常见激活函数

激活函数的发展过程：Sigmoid -> Tanh -> ReLU -> Leaky ReLU -> MaxOut

**sigmoid** 

函数图和导数图

![sigmoid](/assets/img/deeplearning/one-stop/sigma-sigma-prime.jpg)

**tanh**

函数图和导数图

tanh‘ = 1-tanh^2

![tanh](/assets/img/deeplearning/one-stop/tanh-tanh-prime.jpg)

**sigmoid和tanh的区别/联系**

Sigmoid 和 tanh 两个函数非常相似，具有不少相同的性质。简单罗列如下

- 优点：平滑
- 优点：易于求导
- 缺点：幂运算相对耗时
- 缺点：导数值小于 1，反向传播易导致梯度消失（Gradient Vanishing）

对于 Sigmoid 函数来说，它的值域是 (0,1)，因此又有如下特点

- 优点：可以作为概率，辅助模型解释
- 缺点：输出值不以零为中心，可能导致模型收敛速度慢

**这里有一个很重要的问题，为什么不为0中心，就导致收敛慢？**

在梯度更新的时候需要对sigmoid（w*x+b）对w求导， => (w*x+b)' * sigmoid(f(x))' => sig(f(x))*(1-sig(f(x)))* x， 除x项外，其他都是常数，且恒大于0，从第二层起，神经元进过激活函数的输出都是正值，所以后续在做BP的时候，梯度恒为正。

**ReLU**

![relu](/assets/img/deeplearning/one-stop/relu.png)

对比sigmoid类函数主要变化是：

1）单侧抑制；

2）相对宽阔的兴奋边界；

3）稀疏激活性。

存在问题：

ReLU单元比较脆弱并且可能“死掉”，而且是不可逆的，因此导致了数据多样化的丢失。通过合理设置学习率，会降低神经元“死掉”的概率。

**Leaky ReLU**

![leaky-relu](/assets/img/deeplearning/one-stop/leaky-relu.png)

优缺点：

1. 避免ReLU神经元死亡的问题
2. 能有负值输出
3. 输入小于0时权重值是超参数

**MaxOut**

$$
Maxout(x) = max(w_1^T + b_1, w_2^T + b_2)
$$

**特殊的SoftMax**

_softmax一般只作为多分类的模型的最后一层的激活函数_，一般多分类模型的最后一个层的节点数就是类别数，把最后一层的输出总和归一，其中最大的节点值对应的类别就是预测的类别

![softmax](/assets/img/deeplearning/one-stop/softmax.jpg)

原理很简单，重点在于softmax如何进行梯度更新

损失函数一般采用交叉熵

$$
Loss = -\sum_iy_ilna_i
$$

在多分类问题中，N长的label向量其中只有1个1其他全都为0，所以交叉熵中的求和可以忽略掉

![softmax-hand1](/assets/img/deeplearning/one-stop/softmax-hand1.jpg)

![WeChat Image_20190819163357](/assets/img/deeplearning/one-stop/softmax-hand2.jpg)

上面两个图片中有一个问题，为什么节点4要对w5i w6i 求偏导，他们又没有直接连接，因为softmax把节点456连接了起来，所以需要考虑节点4对56的影响；不然网络一次只更新一部分权重

从上面的推导可以看出，对于label为1节点相连的权重求偏导的时候g = (a-1)*o; 对于其他权重g = a*o

**Reference**

[常见激活函数的比较](https://zhuanlan.zhihu.com/p/32610035)

[详解softmax函数以及相关求导过程](https://zhuanlan.zhihu.com/p/25723112)

### 1.3 梯度爆炸/消失

梯度爆炸和梯度消失在某种程度上其实是一回事，在BP过程中，如果激活函数的梯度大于1，那么经过链式求导法则之后，梯度值会以指数形式增加，发生梯度爆炸，反之会以指数形式缩小，发生梯度消失。

解决梯度消失的两个办法

1）、使用 ReLU、LReLU、ELU、maxout 等激活函数

sigmoid函数的梯度随着x的增大或减小和消失，而ReLU不会。

2）、使用批规范化

通过规范化操作将输出信号x规范化到均值为0，方差为1保证网络的稳定性。从上述分析分可以看到，反向传播式子中有w的存在，所以w的大小影响了梯度的消失和爆炸，Batch Normalization 就是通过对每一层的输出规范为均值和方差一致的方法，消除了w带来的放大缩小的影响，进而解决梯度消失和爆炸的问题。

### 1.4 为什么神经网络中使用交叉熵作为损失函数？

**特别注意，这里是说最后输出层的损失函数和激活函数**

***输出层的激活函数，和hidden layer的激活函数是分开设置的***

要说为什么采用交叉熵，就要先看看为什么不用均方误差

均方误差

$$
loss = 0.5*(y-a)^2
$$

a是激活函数的输出结果，如果是sigmoid 

$$
a = sigmoid(z)
$$

其中

$$
z = w*x +b
$$

loss 对w求偏导,链式求导法则可知。 

$$
loss^, = (a-y)a * (1-a)*x
$$

**这其中(a-y)是损失函数导数，a\*(1-a)是激活函数的导数，x是线性函数的导数**，最大值才0.25,当label = 0 predict 接近1 或者label = 1,predict 接近0 的时候，sigmoid的导数值都很小，导致更新很慢，假设一种情况，初始化的时候很极端，正样本的预测值都很接近0，负样本的预测值都很接近1，这种情况下应该是非常错误的，应该马上大跨步的更新权重，但是如果是均方差loss func 并且采用sigmoid，梯度更新很慢。如果采用交叉熵作为损失函数，上面的loss对w求偏导只需要改一下loss函数的导数即可, 交叉熵的导数是

$$
crossentropy^, = (a-y)/a(1-a)
$$

和 sigmoid的导数相乘正好消除掉分母的影响，loss 对w的导数变成，这个时候predict 和label的差越大，梯度更新越快（起码最后一层的梯度更新快）

$$
(a-y)*x
$$

**Reference**

[使用神经网络解决分类问题时，为什么交叉熵误差更好](http://heloowird.com/2017/03/08/diff_errors_of_neural_network/)

### 1.5 输出层的损失函数和激活函数选择

二分类： sigmoid+交叉熵

多分类：softmax+交叉熵

回归：线性激活函数+均方误差

**输出层的激活函数是按照任务来定的，二分类就是sigmoid，多分类是softmax，回归是线性激活函数**，但是在hidden layer中，为了抑制梯度消失，一般采用Relu。当sigmoid/softmax作为最后一层激活函数的时候为了让最后一层也可以加速梯度更新，抑制梯度消失，一般使用交叉熵作为损失函数。

### 1.6 Batch Normalization

**为什么想要去做BN？**

神经网络，特别是深度神经网络，随着梯度更新，各层权重w的值会增大，深层的网络激活函数输出已经到了饱和区（使用饱和激活函数例如sigmoid），浅层的梯度更新缓慢；称为Internal Covariate Shift(ICS)问题

解决梯度饱和问题的思路有两种

1：更换激活函数-Relu，Leaky Relu

2：从激活函数的输入分布入手，修正输入分布，使之落在饱和激活函数的敏感区（0值区附近）

BN层就是从第二个角度出发的。

**算法思路**

首先要说的是Batch Normalization是基于Mini Batch的，并且作用于激活函数之前

对于每一个mini-batch的中的数据的每一个特征，基于特征粒度的z-score normalization，除数+一个基数是为了避免方差为0；

$$
\hat{Z_j} = \frac{Z_j - \mu_j}{\sqrt{\sigma_j^2 + \epsilon}}
$$

这样处理之后，激活函数的输入是均值为0，方差为1的N个特征值；缓解了梯度饱和的问题，使得输入落在激活函数的敏感区间，**可是这样带来了一个更大的问题，经过normalization后的数据的表达能力下降**，为什么？因为均值为0，方差为1 的输入会落在sigmoid函数的0值附近，**进入了非线性激活函数的线性区域，丧失了非线性的表达能力**

因此，BN又引入了两个**可学习（learnable）的参数 ![[公式]](https://www.zhihu.com/equation?tex=%5Cgamma) 与 ![[公式]](https://www.zhihu.com/equation?tex=%5Cbeta)** 。这两个参数的引入是为了恢复数据本身的表达能力，对规范化后的数据进行线性变换，即 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctilde%7BZ_j%7D%3D%5Cgamma_j+%5Chat%7BZ%7D_j%2B%5Cbeta_j) 。特别地，当 ![[公式]](https://www.zhihu.com/equation?tex=%5Cgamma%5E2%3D%5Csigma%5E2%2C%5Cbeta%3D%5Cmu) 时，可以实现等价变换（identity transform）并且保留了原始输入特征的分布信息。除非完全等价还原，否则一定损失了部分表达能力。用数据的表达能力换取模型的更快拟合。

整个过程就是通过normalization把各式各样的分布拉回到标准正态分布，设置一个全局的base，底色，均值为0，方差为1的标准正态分布，然后通过反拉伸和反偏移，把数据分布往原来的方向推回一部分，在表达能力和拟合速度之间取得一个平衡

**预测时候BN层的使用**

预测的时候没有办法计算预测样本的均值和方差，就**采用所有训练样本的均值和方差**，这是对样本分布的真实均值和方差的无偏估计

**BN层总结：**

1. **使得每一层的输入数据的分布相对稳定，加快模型的拟合速度**，深层不需要适应浅层的权重变化，层与层之间解耦合。每一层单独学习
2. **使得模型对参数不敏感**，由于BN层的加入，输入值相对稳定，上一层权重的比例缩放变化在下一层没有体现。避免浅层网络参数的变化蝴蝶效应般的影响到后面的深层网络
3. **BN层允许模型使用饱和激活函数，缓解梯度消失问题**
4. **BN层有一定的正则化效果，抑制过拟合**；对于任意一个样本，和不同的其他样本组合成mini-batch，它自己变化后的值都是不同的，相当于给模型添加了噪声，抑制过拟合

**Reference**

[详解softmax函数以及相关求导过程](https://zhuanlan.zhihu.com/p/25723112)

[Batch Normalization原理与实战](https://zhuanlan.zhihu.com/p/34879333)

## 2 DNN

### 2.1 Perceptron

感知机模型对应于特征空间中将实例划分为正负两类的分离超平面，故而是判别式模型

![perceptron](/assets/img/ML/one-stop-machine-learning/perceptron.png)

原始perceptron采用的激活函数是单位阶跃函数，value set {+1，-1}

由于感知机模型的输出是0和1两个离散的值，如果使用基于分类错误的平方误差，会使得损失函数不连续，更别说是否可导了。所以这里使用下面这个损失函数； 该函数在SVM模型中被称为函数间隔 margin

![perceptron-loss](/assets/img/ML/one-stop-machine-learning/perceptron-loss.png)

其中

M 表示被分类错的样本集

t 表示样本的原始类别

∅(x) 表示经过处理后的输入，w*∅(x) 表示在经过activation function之前的矩阵点乘结果  由于M 是分错类的样本集，w*∅(x) 和 t 始终异号，结果始终大于零

所以损失函数就是 |w*∅(x)| 求和，是一个连续值， 且是凸函数，凸函数可以利用梯度下降法求解，需要求解什么，就对什么求梯度。

![perceptron-gradient](/assets/img/ML/one-stop-machine-learning/perceptron-gradient.png)
![perceptron-gradient1](/assets/img/ML/one-stop-machine-learning/perceptron-gradient1.png)

由上式可以看出，下一次迭代时的权重，由上一次的权重加上学习率加权过的全部输入结果的总和（input set 是分类错的样本集），是明显的batch training，由于巨大的计算量，可以改进为随机梯度下降方法，随机取M中的一个进行梯度下降，此时的梯度下降方法跳跃很大，但是总体上是往最优值跳跃的

![perceptron-sgd](/assets/img/ML/one-stop-machine-learning/perceptron-sgd.png)

每当有分类错误点，权重更新使得分类面朝分类错误点移动

感知机收敛的条件是训练集是线性可分的，如果线性不可分，那么感知机训练过程将永远不会收敛。

感知机一旦训练到没有分类错误点就停止了，也就是即是刚刚移动到一个满足全部分类正确的位置，就停止了，没有进行最优化判断，不同的初值会影响最后的分类面。

[感知机代码实现](https://github.com/JIANGWQ2017/ML/blob/master/perceptron.py)

**Reference**

[感知机](https://www.zybuluo.com/Duanxx/note/425280)



## 3 Time Series Model

### 3.1 RNN

RNN能给传统的神经网络带来了时间维度的考虑，传统的DNN 假设输入之间是完全独立的。假定现在有一个分类的需求，一个球需要判断是往右滚还是往左滚，输入的label是球的坐标，在不给定时间序列的情况下，球左右滚都有可能，但是一定给定时间上的先后顺序，那么球的滚动方向就确定下来了。另外人类的语音输入也是具有强烈的前后关联的，单独把每个词分开看，并不能或者很难看出语句的含义。

RNN则是在前馈神经网络上添加一个传递先前信息的循环，把上一个输入的hidden state 传递给下一个状态，但是如果状态数过多，太早的状态的信息由于梯度消失问题而消失，所以RNN只具有短期记忆

### 3.2 LSTM

谈到LSTM之前首先要说***Recurrent Neural Network**

## 4 NLP

### 4.1 TF-IDF

TF(term frequency) = 词在文章中出现的次数/文章的总词数

IDF(Inverse Document Frequency) = log(语料库总文章数/包含该词的文章数+1)

TF-IDF = TF*IDF

于是一个词的TF-IDF和词出现次数正比，和词出现的文章数反比，因为如果一个词在较少的文章中出现，那么这个词就更有区分度

注意TF计算是针对这一篇文章，而IDF是针对整个语料库

### 4.2 HMM

隐性马尔科夫模型(Hidden Markov Model)用来描述一个含有隐性变量的马尔科夫过程。与传统的马尔科夫过程不同的是，HMM除了具有显性的可见序列，还有隐性序列，遵循两个假设：

1. 齐次马尔科夫假设，任意时刻的隐态只和前一时刻的隐态有关，与其他时刻的状态无关，初始状态由初始概率描述
2. 观测独立假设，任意时刻的观测只和当前时刻的隐态有关。

隐态，观测状态，初始概率，这些名词在后续会解释，在参考博客中有很详细的例子来描述HMM，在此借用一下大佬的描述。假设现在我们手上有**3个不同的骰子**，4面，6面和8面分别用4,6,8表示。骰子质地均匀，**投出每一面的概率相同**，放入一个黑盒中。一次实验过程是，**随机抽出一个骰子**，投掷一次，然后放回盒子。进行多次重复实验。假设现在骰子点数组成的序列为1->2->6->8->5->4，骰子本身组成的序列可能是4->6->6->8->8->4，现在把这个过程抽象一下用来解释HMM的五元组。

| 五元组          | comments                                                     |
| --------------- | ------------------------------------------------------------ |
| 观测序列obs     | 骰子点数组成的序列                                           |
| 隐性状态states  | 骰子本身                                                     |
| 初始概率init_p  | 初始状态的概率，例子中是相同概率1/3                          |
| 转移概率trans_p | 从当前状态转移到下一个状态的概率，例子中是相同的1/3，通常用N*N，N为骰子数的矩阵来描述 |
| 发射概率emit_p  | 给定骰子下，掷出每一面的概率。例子中是骰子均匀，掷出每一面概率相同，通常用N*N，N为骰子能取的不同的点数个数的矩阵来描述 |

HMM根据缺失和已知信息的不同，大体上求解的问题可以分成三类。

1. 知道隐性状态数量(骰子有几种)，知道转移概率，已知观测序列的情况下，求得隐性状态链，**解码(decoding)问题**
2. 知道隐性状态数量，知道转移概率，知道观测序列，想知道观测序列的发生概率，**评估(evaluation)问题**.
3. 知道观测序列，想知道隐藏参数，转移概率，发射概率，初始概率，**学习(learning)问题**

**第一类问题解法**

可以用最大似然状态路径去求解，最大化P(B\|A), A是观测序列，B是参数组合，也就是隐性状态链，我们想知道在显性状态链已经发生的情况下，什么样的隐性状态链产生这个显性状态链的概率最大。为了完成这个任务，也有两种解法，一种是暴力求解。遍历每一种隐性状态链，然后计算在该状态链下产生观测序列的概率。这种解法的计算量随着观测序列的长度指数上升。另一种方法是很有名的**Viterbi algorithm**，这是一种求解最短路径(最长路径可以转换为最短路径)的方法。以观测序列1->2->6->8->5->4来一步一步解释。

​	step 1 观测序列只有‘1’，很显然4面骰子投出1的概率最大，于是当前隐性状态链是‘4’

​	step 2 观测序列是‘1->2’，此时就需要计算第一个骰子分别是4,6,8的情况下，第二个骰子也分别是4,6,8的情况下那种组合的产生观测序列的概率最大，由于此时所有转移概率相同为1/3，整个问题简化为了贪心问题，求第二个骰子的最大概率就行。显然还是4面骰子产生2的概率最大，当前隐性状态链是‘4->4’。但是**当转移概率不同的时候，是需要考虑前面骰子的情况的**，但求解过程也不会很麻烦，因为上一步已经计算了到上一步为止各隐性状态的概率。

​	step 3 重复上述步骤，直到观测序列的最后一个节点，然后倒推出整个似然概率最大的隐性状态链。

**第二类问题解法**

依然可以暴力求解，遍历所有可能的隐性状态链，计算该状态链下产生观测序列的概率，所有概率相加就是结果。另一种方法是forward algorithm 前向算法。依然以观测序列1->2->6->8->5->4来一步一步解释。

step 1 当前观测序列是‘1’, 计算当前情况下产生‘1’的概率

| 骰子  | p1                     |
| ----- | ---------------------- |
| 4     | 1/3 \* 1/4             |
| 6     | 1/3 \* 1/6             |
| 8     | 1/3 \* 1/8             |
| total | sum(p1(4)+p1(6)+p1(8)) |

step 2 当前观测序列是‘1->2’，同样计算当前情况下产生2的概率

| 骰子  | p1       | p2                                 |
| ----- | -------- | ---------------------------------- |
| 4     | 1/3\*1/4 | 1/3\*1/6\* (p1(4) + p1(6) + p1(8)) |
| 6     | 1/3\*1/6 | 1/3\*1/6\*(p1(4)+p1(6)+p1(8))      |
| 8     | 1/3\*1/8 | 1/3\*1/8\*(p1(4)+p1(6)+p1(8))      |
| total | 0.18     | sum(p2(4)+p2(6)+p2(8))             |

step 3 当前观测序列是‘1->2->6’，继续。

| 骰子  | p1       | p2                                 | p3                            |
| ----- | -------- | ---------------------------------- | ----------------------------- |
| 4     | 1/3\*1/4 | 1/3\*1/6\* (p1(4) + p1(6) + p1(8)) | 1/3\*0\*(p2(4)+p2(6)+p2(8))   |
| 6     | 1/3\*1/6 | 1/3\*1/6\*(p1(4)+p1(6)+p1(8))      | 1/3\*1/6\*(p2(4)+p2(6)+p2(8)) |
| 8     | 1/3\*1/8 | 1/3\*1/8\*(p1(4)+p1(6)+p1(8))      | 1/3\*1/8\*(p2(4)+p2(6)+p2(8)) |
| total | 0.18     | sum(p2(4)+p2(6)+p2(8))             | sum(p2(4)+p2(6)+p(8))         |

step 4 以此类推计算到最后一个节点上的total值。

**Reference**

[一文搞懂HMM（隐马尔可夫模型）](https://www.cnblogs.com/skyme/p/4651331.html)

[隐马尔可夫模型（HMM）详解](https://zhuanlan.zhihu.com/p/88362664)

[一站式解决：隐马尔可夫模型（HMM）全过程推导及实现](https://zhuanlan.zhihu.com/p/85454896)

### 4.3 CRF

每次理解新模型的时候，我都希望能通过一个简单易懂的例子来一步一步的从具体到抽象, 而不是上来就是硬推公式，疯狂劝退。好在参考博文的行文逻辑十分符合我的胃口，在此借用。

假设现在有一个分类问题，手上有一堆生活照，从早上到晚上都有，需要给照片打上标签，说明照片中的人是在做什么事情。我们当然可以直接根据单个照片的特征来进行分类，用一些已经标记好的照片训练一个模型，然后给未分类的照片打标签。这样固然可行，但是放弃了照片之间的时间关系，比如上一张照片在切洋葱，下一张照片人的眼睛闭上，那么大概率是因为洋葱辣眼睛才闭上的眼睛，而不是睡觉。

引申一下，CRF目前最合适的使用场景是词性标注，假设现在有一个句子是“I drank coffee at Timmy”，我们对每一个词打标签，I(名词) drank(动词) coffee(名词) at(介词) Timmy(名词)。当然有很多种标签组合，那么怎么知道哪一种组合更好呢？这就需要我们定义**特征函数**，或者说**特征函数集合**，给定标记序列，遍历所有特征函数，用每一个特征函数给标记序列打分，最后把分数加起来就是当前标记序列的总分数，分数最高的标记就是最好的标记序列。

一个仅考虑前后两个词性关联的线性特征函数f接受4个参数，输出是0/1，如果句子符合模式返回1，否则返回0

1. 句子$s$，待标记句子
2. $i$，句子$s$中的第$i$个单词
3. $l\_i$表示给第$i$个单词标记的词性
4. $l\_i-1$表示给第$i-1$个单词标记的词性

给定特征函数$f\_i$一个权重$\lambda\_i$ ,那么句子$s$给定标记$l$的情况下分数等于

$$
score(l|s) = \sum_{j=1}^{m}\sum_{i=1}^{n}\lambda_jf_j(s,i,l_i,l_{i-1})
$$

外部求和是所有特征函数评分求和，内部求和是句子每个位置的单词特征值求和，然后经过SoftMax激活函数，就可以得到每一种标记的‘概率’

$$
p(l|s) = \frac{e^{score(l|s)}}{\sum_{\hat{l}}e^{score(\hat{l}|s)}}
$$

**CRF和HMM的比较**

以同样做词性标记任务来对比，HMM观测序列句子$s$ 和标记序列词性$l$之间的联合概率分布

$$
p(l,s) = p(l_1)p(w_1|l_1)\prod_ip(l_i|l_{i-1})p(w_i|l_i)
$$

其中$p(l_i|l_{i-1})$ 表示转移概率，从上一个词性标记到下一个词性标记的概率，$p(w_i|l_i)$表示发射概率，在当前词性标注下，当前单词是$w_i$的概率。初始概率需要额外单独列出。

对HMM联合概率公式取对数
$$
logp(l,s) = logp(l_1) + logp(w_1|l_1) + \sum_{1}^{n}logp(l_i|l_{i-1}) + \sum_{1}^{n}p(w_i|l_i)
$$


**Reference**

[如何轻松愉快地理解条件随机场（CRF）？](https://blog.csdn.net/dcx_abc/article/details/78319246)